#!/usr/bin/env python3
"""
DAY 2 - –ß–ï–°–¢–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –î–í–£–• –ë–≠–ö–¢–ï–°–¢–û–í
===========================================

–¶–µ–ª—å: –ü–æ–Ω—è—Ç—å –ò–ú–ï–ù–ù–û –∫–∞–∫ –º–æ–¥–µ–ª–∏ —Å—á–∏—Ç–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

–¢–ï–°–¢ 1: Comprehensive backtest (–∫–∞–∫ –≤ audit)
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Ü–µ–Ω—É –∑–∞ 96 –±–∞—Ä–æ–≤
- –ù–∏–∫–∞–∫–æ–≥–æ SL
- –ù–∏–∫–∞–∫–∏—Ö –∏–∑–¥–µ—Ä–∂–µ–∫
- –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Å–∏–≥–Ω–∞–ª–æ–≤

–¢–ï–°–¢ 2: Realistic backtest (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏)
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç TP +1.0% –∏ SL -0.5%
- –ò–∑–¥–µ—Ä–∂–∫–∏ 0.3%
- Exit –ø—Ä–∏ –ü–ï–†–í–û–ú —Å–æ–±—ã—Ç–∏–∏
- –†–µ–∞–ª—å–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è

–ù–∞ –û–î–ù–ò–• –ò –¢–ï–• –ñ–ï –¥–∞–Ω–Ω—ã—Ö ‚Üí –≤–∏–¥–∏–º —Ç–æ—á–Ω—É—é —Ä–∞–∑–Ω–∏—Ü—É
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import json
from datetime import datetime
import joblib
import xgboost as xgb

# ============================================================================
# –ö–û–ù–§–ò–ì
# ============================================================================
CONFIG = {
    'asset': 'BTC',
    'timeframe': '15m',
    'forward_window': 96,  # 24 —á–∞—Å–æ–≤ –Ω–∞ 15m
    'tp_percent': 1.0,
    'sl_percent': -0.5,
    'costs_percent': 0.3,
    'ml_threshold': 0.50,
}

# ============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ò –ú–û–î–ï–õ–ò
# ============================================================================

def load_ml_model_and_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é ML –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ"""
    print("=" * 80)
    print("LOADING ML MODEL AND DATA")
    print("=" * 80)

    model_path = Path("models/xgboost_normalized_model.json")
    scaler_path = Path("models/xgboost_normalized_scaler.pkl")
    features_path = Path("models/xgboost_normalized_features.json")

    if not model_path.exists():
        print(f"‚ùå Model not found: {model_path}")
        return None, None, None, None

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = xgb.Booster()
    model.load_model(str(model_path))
    print(f"‚úÖ Model loaded: {model_path}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º scaler
    scaler = joblib.load(scaler_path)
    print(f"‚úÖ Scaler loaded: {scaler_path}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º features
    with open(features_path) as f:
        features_info = json.load(f)
    feature_names = features_info['features']
    print(f"‚úÖ Features loaded: {len(feature_names)} features")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    data_path = Path(f"data/{CONFIG['asset']}_{CONFIG['timeframe']}_normalized.parquet")
    if not data_path.exists():
        print(f"‚ùå Data not found: {data_path}")
        return None, None, None, None

    df = pd.read_parquet(data_path)
    print(f"‚úÖ Data loaded: {len(df)} bars")

    return model, scaler, feature_names, df


def extract_features(df: pd.DataFrame, feature_names: List[str]) -> pd.DataFrame:
    """–ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nExtracting features...")

    # –î–ª—è —ç—Ç–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ—Å—Ç–æ –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ N —Ñ–∏—á –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
    available_features = [f for f in feature_names if f in df.columns]
    print(f"Available features: {len(available_features)}/{len(feature_names)}")

    features_df = df[available_features].copy()
    return features_df


# ============================================================================
# –¢–ï–°–¢ 1: COMPREHENSIVE BACKTEST (max price –∑–∞ 96 –±–∞—Ä–æ–≤)
# ============================================================================

def comprehensive_backtest(model, scaler, features_df: pd.DataFrame, df: pd.DataFrame,
                          feature_names: List[str]) -> Dict:
    """
    COMPREHENSIVE: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Ü–µ–Ω—É –∑–∞ 96 –±–∞—Ä–æ–≤
    (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º audit)
    """
    print("\n" + "=" * 80)
    print("TEST 1: COMPREHENSIVE BACKTEST (Max Price –∑–∞ 96 –±–∞—Ä–æ–≤)")
    print("=" * 80)

    forward_window = CONFIG['forward_window']
    tp_target = CONFIG['tp_percent'] / 100

    results = {
        'entries': [],
        'wins': 0,
        'losses': 0,
        'trades': 0,
        'ml_probabilities': [],
        'exit_prices': [],
        'profit_percents': [],
    }

    # –ù—É–∂–Ω–æ –∏–º–µ—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
    min_samples = max(100, len(features_df.columns))

    for i in range(min_samples, len(df) - forward_window - 1):
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏—á–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ä–∞
        try:
            # –ë–µ—Ä—ë–º —Ñ–∏—á–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–Ω–¥–µ–∫—Å–æ–º
            current_idx = min(i, len(features_df) - 1)
            X_current = features_df.iloc[current_idx].values.reshape(1, -1)

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
            X_scaled = scaler.transform(X_current)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ML
            ml_prob = model.predict(xgb.DMatrix(X_scaled))[0]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–≥–Ω–∞–ª
            if ml_prob < CONFIG['ml_threshold']:
                continue

            # Entry price
            entry_price = df.iloc[i]['close']

            # COMPREHENSIVE: –±–µ—Ä—ë–º –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–£–Æ —Ü–µ–Ω—É –∑–∞ forward_window –±–∞—Ä–æ–≤
            max_price = df.iloc[i:i+forward_window]['high'].max()
            profit = (max_price - entry_price) / entry_price

            # –†–µ–∑—É–ª—å—Ç–∞—Ç
            if profit >= tp_target:
                result = 'WIN'
                results['wins'] += 1
            else:
                result = 'LOSS'
                results['losses'] += 1

            results['trades'] += 1
            results['ml_probabilities'].append(ml_prob)
            results['exit_prices'].append(max_price)
            results['profit_percents'].append(profit * 100)

            if results['trades'] % 10000 == 0:
                print(f"  Processed {results['trades']} trades...")

        except Exception as e:
            continue

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    wr = results['wins'] / results['trades'] * 100 if results['trades'] > 0 else 0
    avg_win = np.mean([p for p in results['profit_percents'] if p > 0]) if results['wins'] > 0 else 0
    avg_loss = np.mean([p for p in results['profit_percents'] if p < 0]) if results['losses'] > 0 else 0
    pf = (results['wins'] * avg_win) / (results['losses'] * abs(avg_loss)) if results['losses'] > 0 and avg_loss != 0 else 0

    print(f"\nüìä COMPREHENSIVE RESULTS:")
    print(f"  Trades: {results['trades']:,}")
    print(f"  Wins: {results['wins']:,}")
    print(f"  Losses: {results['losses']:,}")
    print(f"  Win Rate: {wr:.1f}%")
    print(f"  Avg Win: {avg_win:.2f}%")
    print(f"  Avg Loss: {avg_loss:.2f}%")
    print(f"  Profit Factor: {pf:.2f}")
    print(f"  ML Probability: min={np.min(results['ml_probabilities']):.3f}, " +
          f"avg={np.mean(results['ml_probabilities']):.3f}, " +
          f"max={np.max(results['ml_probabilities']):.3f}")

    return {
        'type': 'comprehensive',
        'trades': results['trades'],
        'wins': results['wins'],
        'losses': results['losses'],
        'wr': wr,
        'avg_win': avg_win,
        'avg_loss': avg_loss,
        'pf': pf,
    }


# ============================================================================
# –¢–ï–°–¢ 2: REALISTIC BACKTEST (TP/SL —Å –∏–∑–¥–µ—Ä–∂–∫–∞–º–∏)
# ============================================================================

def realistic_backtest(model, scaler, features_df: pd.DataFrame, df: pd.DataFrame,
                      feature_names: List[str]) -> Dict:
    """
    REALISTIC: –∏—Å–ø–æ–ª—å–∑—É–µ–º TP/SL –∏ –∏–∑–¥–µ—Ä–∂–∫–∏
    (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ)
    """
    print("\n" + "=" * 80)
    print("TEST 2: REALISTIC BACKTEST (TP/SL + Costs)")
    print("=" * 80)

    forward_window = CONFIG['forward_window']
    tp_pct = CONFIG['tp_percent'] / 100
    sl_pct = CONFIG['sl_percent'] / 100
    costs = CONFIG['costs_percent'] / 100

    results = {
        'trades': 0,
        'wins': 0,
        'losses': 0,
        'tp_exits': 0,
        'sl_exits': 0,
        'time_exits': 0,
        'profit_percents': [],
        'ml_probabilities': [],
    }

    min_samples = max(100, len(features_df.columns))

    for i in range(min_samples, len(df) - forward_window - 1):
        try:
            current_idx = min(i, len(features_df) - 1)
            X_current = features_df.iloc[current_idx].values.reshape(1, -1)
            X_scaled = scaler.transform(X_current)

            ml_prob = model.predict(xgb.DMatrix(X_scaled))[0]

            if ml_prob < CONFIG['ml_threshold']:
                continue

            entry_price = df.iloc[i]['close']

            # –í—ã—á–∏—Å–ª—è–µ–º TP –∏ SL —É—Ä–æ–≤–Ω–∏ —Å —É—á—ë—Ç–æ–º –∏–∑–¥–µ—Ä–∂–µ–∫
            tp_level = entry_price * (1 + tp_pct + costs)
            sl_level = entry_price * (1 + sl_pct - costs)

            # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –±–∞—Ä–∞–º forward_window –∏ –∏—â–µ–º –ø–µ—Ä–≤—ã–π exit
            exit_reason = None
            exit_price = None
            profit = None

            for j in range(1, forward_window + 1):
                if i + j >= len(df):
                    break

                bar = df.iloc[i + j]

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º TP
                if bar['high'] >= tp_level:
                    exit_reason = 'TP'
                    exit_price = tp_level
                    profit = (tp_level - entry_price) / entry_price * 100
                    results['tp_exits'] += 1
                    break

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º SL
                elif bar['low'] <= sl_level:
                    exit_reason = 'SL'
                    exit_price = sl_level
                    profit = (sl_level - entry_price) / entry_price * 100
                    results['sl_exits'] += 1
                    break

            # –ï—Å–ª–∏ –Ω–µ –≤—ã–±–∏–ª–∏ TP/SL, –≤—ã—Ö–æ–¥–∏–º –ø–æ Time
            if exit_reason is None:
                exit_reason = 'TIME'
                exit_price = df.iloc[min(i + forward_window, len(df) - 1)]['close']
                profit = (exit_price - entry_price) / entry_price * 100
                results['time_exits'] += 1

            # –†–µ–∑—É–ª—å—Ç–∞—Ç
            if profit >= 0:
                results['wins'] += 1
            else:
                results['losses'] += 1

            results['trades'] += 1
            results['profit_percents'].append(profit)
            results['ml_probabilities'].append(ml_prob)

            if results['trades'] % 10000 == 0:
                print(f"  Processed {results['trades']} trades...")

        except Exception as e:
            continue

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    wr = results['wins'] / results['trades'] * 100 if results['trades'] > 0 else 0
    avg_profit = np.mean(results['profit_percents']) if results['profit_percents'] else 0

    print(f"\nüìä REALISTIC RESULTS:")
    print(f"  Trades: {results['trades']:,}")
    print(f"  Wins: {results['wins']:,}")
    print(f"  Losses: {results['losses']:,}")
    print(f"  Win Rate: {wr:.1f}%")
    print(f"  TP exits: {results['tp_exits']:,}")
    print(f"  SL exits: {results['sl_exits']:,}")
    print(f"  TIME exits: {results['time_exits']:,}")
    print(f"  Avg Profit: {avg_profit:.2f}%")

    return {
        'type': 'realistic',
        'trades': results['trades'],
        'wins': results['wins'],
        'losses': results['losses'],
        'wr': wr,
        'tp_exits': results['tp_exits'],
        'sl_exits': results['sl_exits'],
        'time_exits': results['time_exits'],
    }


# ============================================================================
# –°–†–ê–í–ù–ï–ù–ò–ï
# ============================================================================

def compare_results(comp_result: Dict, real_result: Dict):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
    print("\n" + "=" * 80)
    print("–°–†–ê–í–ù–ï–ù–ò–ï: Comprehensive vs Realistic")
    print("=" * 80)

    print(f"\nüìä WIN RATE:")
    print(f"  Comprehensive: {comp_result['wr']:.1f}%")
    print(f"  Realistic:     {real_result['wr']:.1f}%")
    print(f"  Â∑ÆÂºÇ (difference): {comp_result['wr'] - real_result['wr']:.1f}%")

    print(f"\nüìä TRADES:")
    print(f"  Comprehensive: {comp_result['trades']:,}")
    print(f"  Realistic:     {real_result['trades']:,}")

    if real_result['trades'] > 0:
        print(f"\nüìä EXIT REASONS (Realistic):")
        print(f"  TP:   {real_result['tp_exits']:,} ({real_result['tp_exits']/real_result['trades']*100:.1f}%)")
        print(f"  SL:   {real_result['sl_exits']:,} ({real_result['sl_exits']/real_result['trades']*100:.1f}%)")
        print(f"  TIME: {real_result['time_exits']:,} ({real_result['time_exits']/real_result['trades']*100:.1f}%)")

    print(f"\nüí° –í–´–í–û–î–´:")
    wr_diff = comp_result['wr'] - real_result['wr']

    if wr_diff > 20:
        print(f"  ‚ö†Ô∏è  –ë–û–õ–¨–®–ê–Ø –†–ê–ó–ù–ò–¶–ê ({wr_diff:.1f}%)")
        print(f"  –ü—Ä–æ–±–ª–µ–º–∞: SL —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ?")
        print(f"  –†–µ—à–µ–Ω–∏–µ: –£–≤–µ–ª–∏—á–∏—Ç—å SL, –∏–ª–∏ —É–±—Ä–∞—Ç—å SL —Å–æ–≤—Å–µ–º?")
    elif wr_diff > 10:
        print(f"  ‚ö†Ô∏è  –ó–∞–º–µ—Ç–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ ({wr_diff:.1f}%)")
        print(f"  –ù–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è TP/SL, –Ω–æ –Ω—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å")
    else:
        print(f"  ‚úÖ –ü—Ä–∏–µ–º–ª–µ–º–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ ({wr_diff:.1f}%)")
        print(f"  –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ")


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("\n" + "=" * 80)
    print("DAY 2: ML MODEL DIAGNOSTIC - COMPREHENSIVE vs REALISTIC")
    print("=" * 80)
    print(f"Asset: {CONFIG['asset']}")
    print(f"Timeframe: {CONFIG['timeframe']}")
    print(f"ML Threshold: {CONFIG['ml_threshold']}")
    print(f"TP: {CONFIG['tp_percent']}% | SL: {CONFIG['sl_percent']}% | Costs: {CONFIG['costs_percent']}%")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º
    model, scaler, feature_names, df = load_ml_model_and_data()
    if model is None:
        print("‚ùå Failed to load data")
        return

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏
    features_df = extract_features(df, feature_names)

    # –¢–µ—Å—Ç 1: Comprehensive
    comp_result = comprehensive_backtest(model, scaler, features_df, df, feature_names)

    # –¢–µ—Å—Ç 2: Realistic
    real_result = realistic_backtest(model, scaler, features_df, df, feature_names)

    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    compare_results(comp_result, real_result)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_file = Path("reports/ml_diagnostic_comprehensive_vs_realistic.json")
    results_file.parent.mkdir(parents=True, exist_ok=True)

    with open(results_file, 'w') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'comprehensive': comp_result,
            'realistic': real_result,
        }, f, indent=2)

    print(f"\n‚úÖ Results saved to {results_file}")


if __name__ == '__main__':
    main()

"""Train XGBoost v3
================

–û–±—É—á–µ–Ω–∏–µ XGBoost –º–æ–¥–µ–ª–∏ –Ω–∞ 74 features (single timeframe).

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/train_xgboost_v3.py

–†–µ–∑—É–ª—å—Ç–∞—Ç:
    models/xgboost_v3_{coin}_{tf}.json
    models/xgboost_v3_{coin}_{tf}_metadata.json
"""

import pandas as pd
import numpy as np
import xgboost as xgb
import json
from pathlib import Path
from datetime import datetime
from sklearn.metrics import (
    f1_score, roc_auc_score, precision_score, 
    recall_score, accuracy_score, confusion_matrix,
    precision_recall_curve
)


def load_data(parquet_path: str) -> tuple:
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ parquet.
    
    Returns
    -------
    tuple
        (X, y, feature_names, df)
    """
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞: {parquet_path}")
    df = pd.read_parquet(parquet_path)
    
    print(f"   –†–∞–∑–º–µ—Ä: {len(df):,} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    print(f"   –ü–µ—Ä–∏–æ–¥: {df.index[0]} ‚Äî {df.index[-1]}")
    
    if 'target' not in df.columns:
        raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'target' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
    
    X = df.drop(columns=['target'])
    y = df['target']
    
    inf_count = np.isinf(X.values).sum()
    nan_count = np.isnan(X.values).sum()
    
    if inf_count > 0 or nan_count > 0:
        print(f"   ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ inf: {inf_count}, nan: {nan_count}")
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(0)
    
    print(f"   Features: {X.shape[1]}")
    print(f"   Class balance: {y.mean():.2%} (class 1)")
    
    return X, y, list(X.columns), df


def temporal_split(X, y, train_ratio: float = 0.8) -> tuple:
    """
    –í—Ä–µ–º–µ–Ω–Ω–æ–π split (–±–µ–∑ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è).
    """
    split_idx = int(len(X) * train_ratio)
    
    X_train = X.iloc[:split_idx]
    X_test = X.iloc[split_idx:]
    y_train = y.iloc[:split_idx]
    y_test = y.iloc[split_idx:]
    
    print(f"\nüìÑ Split:")
    print(f"   Train: {len(X_train):,} samples ({train_ratio:.0%})")
    print(f"   Test:  {len(X_test):,} samples ({1-train_ratio:.0%})")
    print(f"   Train class 1: {y_train.mean():.2%}")
    print(f"   Test class 1:  {y_test.mean():.2%}")
    
    return X_train, X_test, y_train, y_test, split_idx


def train_model(X_train, y_train, X_test, y_test, params: dict = None) -> xgb.XGBClassifier:
    """
    –û–±—É—á–∏—Ç—å XGBoost –º–æ–¥–µ–ª—å.
    """
    neg_count = (y_train == 0).sum()
    pos_count = (y_train == 1).sum()
    scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1.0
    
    default_params = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'max_depth': 4,
        'learning_rate': 0.01,
        'n_estimators': 500,
        'min_child_weight': 5,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 1.0,
        'scale_pos_weight': scale_pos_weight,
        'random_state': 42,
        'n_jobs': -1,
        'early_stopping_rounds': 50
    }
    
    if params:
        default_params.update(params)
    
    print(f"\nüîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    for k, v in default_params.items():
        if k not in ['n_jobs', 'random_state']:
            print(f"   {k}: {v}")
    
    print(f"\nüöÄ –û–±—É—á–µ–Ω–∏–µ...")
    
    model = xgb.XGBClassifier(**default_params)
    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_test, y_test)],
        verbose=50
    )
    
    return model

def evaluate_model(model, X_test, y_test, threshold: float = 0.5) -> dict:
    """
    –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏.
    """
    y_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_proba >= threshold).astype(int)
    
    metrics = {
        "auc": roc_auc_score(y_test, y_proba),
        "f1": f1_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred, zero_division=0),
        "recall": recall_score(y_test, y_pred, zero_division=0),
        "accuracy": accuracy_score(y_test, y_pred),
        "threshold": threshold
    }
    
    cm = confusion_matrix(y_test, y_pred)
    metrics["confusion_matrix"] = cm.tolist()
    metrics["true_negatives"] = int(cm[0, 0])
    metrics["false_positives"] = int(cm[0, 1])
    metrics["false_negatives"] = int(cm[1, 0])
    metrics["true_positives"] = int(cm[1, 1])
    
    return metrics


def find_optimal_threshold(model, X_test, y_test) -> dict:
    """
    –ù–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π threshold –ø–æ F1.
    """
    y_proba = model.predict_proba(X_test)[:, 1]
    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)
    best_idx = np.argmax(f1_scores[:-1])
    
    return {
        "optimal_threshold": float(thresholds[best_idx]),
        "best_f1": float(f1_scores[best_idx]),
        "precision_at_best": float(precision[best_idx]),
        "recall_at_best": float(recall[best_idx])
    }


def save_model(model: xgb.XGBClassifier, output_path: str, feature_names: list, metrics: dict, threshold_info: dict, parquet_path: str):
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –∏ metadata.
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    model.save_model(str(output_path))
    print(f"\nüíæ –ú–æ–¥–µ–ª—å: {output_path}")
    
    metadata = {
        "created_at": datetime.now().isoformat(),
        "source_data": parquet_path,
        "n_features": len(feature_names),
        "feature_names": feature_names,
        "metrics": metrics,
        "optimal_threshold": threshold_info,
        "model_params": model.get_params()
    }
    
    metadata_path = output_path.parent / (output_path.stem + '_metadata.json')
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2, default=str)
    print(f"üíæ Metadata: {metadata_path}")


def print_results(metrics: dict, threshold_info: dict, criteria: dict):
    """
    –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫—Ä–∏—Ç–µ—Ä–∏–∏.
    """
    print("\n" + "="*60)
    print("üìÑ –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("="*60)
    print(f"\n   Threshold 0.5:")
    print(f"   AUC:       {metrics['auc']:.4f}")
    print(f"   F1:        {metrics['f1']:.4f}")
    print(f"   Precision: {metrics['precision']:.4f}")
    print(f"   Recall:    {metrics['recall']:.4f}")
    print(f"\n   Optimal threshold ({threshold_info['optimal_threshold']:.3f}):")
    print(f"   F1:        {threshold_info['best_f1']:.4f}")
    print(f"   Precision: {threshold_info['precision_at_best']:.4f}")
    print(f"   Recall:    {threshold_info['recall_at_best']:.4f}")
    print(f"\n   Confusion Matrix:")
    print(f"   TN: {metrics['true_negatives']:,}  FP: {metrics['false_positives']:,}")
    print(f"   FN: {metrics['false_negatives']:,}  TP: {metrics['true_positives']:,}")
    print("\n" + "="*60)
    print("‚úÖ –ö–†–ò–¢–ï–†–ò–ò")
    print("="*60)
    checks = {
        "AUC > 0.60": metrics['auc'] > criteria.get('auc', 0.60),
        "F1 > 0.50": threshold_info['best_f1'] > criteria.get('f1', 0.50),
        "Precision > 0.45": threshold_info['precision_at_best'] > criteria.get('precision', 0.45),
        "Recall > 0.40": threshold_info['recall_at_best'] > criteria.get('recall', 0.40)
    }
    all_pass = True
    for name, passed in checks.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"   {status} {name}")
        if not passed:
            all_pass = False
    print("\n" + "="*60)
    if all_pass:
        print("üéâ –í–°–ï –ö–†–ò–¢–ï–†–ò–ò –ü–†–û–ô–î–ï–ù–´!")
    else:
        print("‚ö†Ô∏è  –ù–ï –í–°–ï –ö–†–ò–¢–ï–†–ò–ò –ü–†–û–ô–î–ï–ù–´")
    print("="*60)
    return all_pass


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("\n" + "="*60)
    print("üöÄ XGBOOST TRAINING v3")
    print("="*60)
    
    PARQUET_PATH = "data/features/BTC_USDT_15m_features.parquet"
    OUTPUT_PATH = "models/xgboost_v3_btc_15m.json"
    CRITERIA = {
        "auc": 0.60,
        "f1": 0.50,
        "precision": 0.45,
        "recall": 0.40
    }
    
    X, y, feature_names, df = load_data(PARQUET_PATH)
    X_train, X_test, y_train, y_test, split_idx = temporal_split(X, y, 0.8)
    model = train_model(X_train, y_train, X_test, y_test)
    metrics = evaluate_model(model, X_test, y_test, threshold=0.5)
    threshold_info = find_optimal_threshold(model, X_test, y_test)
    all_pass = print_results(metrics, threshold_info, CRITERIA)
    
    save_model(
        model=model,
        output_path=OUTPUT_PATH,
        feature_names=feature_names,
        metrics=metrics,
        threshold_info=threshold_info,
        parquet_path=PARQUET_PATH
    )
    
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
    return all_pass


if __name__ == "__main__":
    main()

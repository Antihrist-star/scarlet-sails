#!/usr/bin/env python3
"""
ĞŸĞĞ›ĞĞ«Ğ™ Ğ˜ĞĞ’Ğ•ĞĞ¢ĞĞ Ğ¬ Ğ’Ğ¡Ğ•Ğ¥ Ğ Ğ•Ğ¡Ğ£Ğ Ğ¡ĞĞ’
================================

Ğ¡ĞºĞ°Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚:
1. Ğ’ÑĞµ OHLCV Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (14 Ğ¼Ğ¾Ğ½ĞµÑ‚ Ã— 4 Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼Ğ°)
2. Ğ’ÑĞµ XGBoost Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
3. Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ñ‹ Ğ´Ğ°Ñ‚ Ğ¸ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ¸
4. Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½Ğ° Ñ‚Ğ¾Ğ³Ğ¾, Ñ Ñ‡ĞµĞ¼ Ğ¼Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼
"""

import os
import sys
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime
import json

sys.path.append(str(Path(__file__).parent.parent))

# ============================================================================
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# ============================================================================

PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIRS = [
    PROJECT_ROOT / "data" / "raw",
    PROJECT_ROOT / "data",
    PROJECT_ROOT / "datasets",
]
MODEL_DIRS = [
    PROJECT_ROOT / "models",
    PROJECT_ROOT / "model",
    PROJECT_ROOT / "ml_models",
]

# ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¼Ğ¾Ğ½ĞµÑ‚Ñ‹
COINS = ["BTC", "ETH", "SOL", "ALGO", "AVAX", "DOT", "ENA", "HBAR", "LDO", "LINK", "LTC", "ONDO", "SUI", "UNI"]
TIMEFRAMES = ["15m", "1h", "4h", "1d", "1M", "5m", "15min", "1hour", "4hour", "1day"]

# ============================================================================
# UTILS
# ============================================================================

def find_files(root_dir, extensions=['.parquet', '.csv', '.pkl', '.feather']):
    """ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ²ÑĞµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
    files = []
    if not root_dir.exists():
        return files

    for ext in extensions:
        files.extend(root_dir.glob(f"**/*{ext}"))
    return files

def parse_filename(filename):
    """ĞŸĞ¾Ğ¿Ñ‹Ñ‚Ğ°Ñ‚ÑŒÑÑ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞ¸Ñ‚ÑŒ Ğ¸Ğ¼Ñ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ñƒ Ğ¸ Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼"""
    name = filename.stem.upper()

    coin = None
    timeframe = None

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¼Ğ¾Ğ½ĞµÑ‚Ñ‹
    for c in COINS:
        if c in name:
            coin = c
            break

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼Ñ‹
    for tf in TIMEFRAMES:
        if tf.upper() in name:
            timeframe = tf
            break

    return coin, timeframe

def analyze_ohlcv(filepath):
    """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ OHLCV Ñ„Ğ°Ğ¹Ğ»"""
    try:
        if filepath.suffix == '.parquet':
            df = pd.read_parquet(filepath)
        elif filepath.suffix == '.csv':
            df = pd.read_csv(filepath, nrows=10000)  # ĞĞµ Ğ³Ñ€ÑƒĞ·Ğ¸Ğ¼ Ğ²ÑÑ‘ Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸
        else:
            return None

        if len(df) == 0:
            return {'status': 'EMPTY', 'rows': 0}

        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ñ‹ Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½ĞµĞ¼
        time_cols = [col for col in df.columns if 'time' in col.lower() or 'date' in col.lower() or 'timestamp' in col.lower()]

        info = {
            'status': 'OK',
            'rows': len(df),
            'columns': list(df.columns),
            'dtypes': {col: str(df[col].dtype) for col in df.columns},
        }

        # ĞŸĞ¾Ğ¿Ñ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ´Ğ°Ñ‚
        if time_cols:
            time_col = time_cols[0]
            try:
                dates = pd.to_datetime(df[time_col])
                info['date_min'] = str(dates.min())
                info['date_max'] = str(dates.max())
                info['date_range_days'] = (dates.max() - dates.min()).days
            except:
                pass

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ OHLCV
        required = ['open', 'high', 'low', 'close', 'volume']
        has_ohlcv = [col.lower() in [c.lower() for c in df.columns] for col in required]
        info['has_ohlcv'] = all(has_ohlcv)

        return info
    except Exception as e:
        return {'status': 'ERROR', 'error': str(e)}

def check_model_file(filepath):
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ñ„Ğ°Ğ¹Ğ» ML Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
    try:
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ
        if filepath.suffix == '.json':
            with open(filepath, 'r') as f:
                data = json.load(f)
            return {
                'status': 'OK',
                'type': 'XGBoost JSON',
                'size_kb': filepath.stat().st_size / 1024,
                'keys': list(data.keys()) if isinstance(data, dict) else 'Not a dict'
            }
        elif filepath.suffix == '.pkl':
            return {
                'status': 'OK',
                'type': 'Pickle',
                'size_kb': filepath.stat().st_size / 1024,
            }
        elif filepath.suffix == '.joblib':
            return {
                'status': 'OK',
                'type': 'Joblib',
                'size_kb': filepath.stat().st_size / 1024,
            }
        else:
            return {
                'status': 'UNKNOWN',
                'type': filepath.suffix,
                'size_kb': filepath.stat().st_size / 1024,
            }
    except Exception as e:
        return {'status': 'ERROR', 'error': str(e)}

# ============================================================================
# MAIN SCANNING
# ============================================================================

def main():
    print("\n" + "="*80)
    print("ĞŸĞĞ›ĞĞ«Ğ™ Ğ˜ĞĞ’Ğ•ĞĞ¢ĞĞ Ğ¬ Ğ Ğ•Ğ¡Ğ£Ğ Ğ¡ĞĞ’ SCARLET-SAILS")
    print("="*80)
    print(f"Ğ’Ñ€ĞµĞ¼Ñ ÑĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Project root: {PROJECT_ROOT}\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PART 1: Ğ”ĞĞĞĞ«Ğ• (OHLCV)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "-"*80)
    print("PART 1: OHLCV DATA FILES")
    print("-"*80)

    ohlcv_files = []
    for data_dir in DATA_DIRS:
        ohlcv_files.extend(find_files(data_dir, ['.parquet', '.csv', '.feather']))

    if not ohlcv_files:
        print("âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…!")
    else:
        print(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: {len(ohlcv_files)}\n")

        # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ°Ğ¼ Ğ¸ Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼Ğ°Ğ¼
        data_by_pair = {}

        for filepath in sorted(ohlcv_files):
            coin, timeframe = parse_filename(filepath)
            info = analyze_ohlcv(filepath)

            if info is None:
                continue

            pair = f"{coin}_{timeframe}" if coin and timeframe else filepath.name

            if pair not in data_by_pair:
                data_by_pair[pair] = {
                    'file': filepath,
                    'info': info,
                    'coin': coin,
                    'timeframe': timeframe
                }

        # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ
        print(f"{'Pair':<20} {'Rows':<10} {'Date Min':<15} {'Date Max':<15} {'Days':<8} {'Status':<10}")
        print("-" * 90)

        for pair, data in sorted(data_by_pair.items()):
            info = data['info']
            rows = info.get('rows', '?')
            date_min = info.get('date_min', '?')[:10]
            date_max = info.get('date_max', '?')[:10]
            days = info.get('date_range_days', '?')
            status = info.get('status', 'UNKNOWN')

            status_icon = "âœ…" if status == "OK" else "âŒ"
            print(f"{pair:<20} {rows:<10} {date_min:<15} {date_max:<15} {days:<8} {status_icon}")

        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
        print("\nğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ Ğ”ĞĞĞĞ«Ğ¥:")
        total_files = len(data_by_pair)
        ok_files = sum(1 for d in data_by_pair.values() if d['info'].get('status') == 'OK')
        empty_files = sum(1 for d in data_by_pair.values() if d['info'].get('status') == 'EMPTY')
        error_files = sum(1 for d in data_by_pair.values() if d['info'].get('status') == 'ERROR')

        print(f"  Ğ’ÑĞµĞ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: {total_files}")
        print(f"  âœ… OK: {ok_files}")
        print(f"  ğŸŸ¡ EMPTY: {empty_files}")
        print(f"  âŒ ERROR: {error_files}")

        # ĞšĞ°ĞºĞ¸Ğµ Ğ¼Ğ¾Ğ½ĞµÑ‚Ñ‹ ĞµÑÑ‚ÑŒ
        coins_found = set(d['coin'] for d in data_by_pair.values() if d['coin'])
        timeframes_found = set(d['timeframe'] for d in data_by_pair.values() if d['timeframe'])

        print(f"\n  ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ½ĞµÑ‚Ñ‹ ({len(coins_found)}): {', '.join(sorted(coins_found))}")
        print(f"  ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼Ñ‹ ({len(timeframes_found)}): {', '.join(sorted(timeframes_found))}")

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ
        print(f"\n  ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ñ… Ğ¿Ğ°Ñ€: {len(COINS)} Ğ¼Ğ¾Ğ½ĞµÑ‚ Ã— {len(TIMEFRAMES)} Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼Ğ¾Ğ² = {len(COINS) * len(TIMEFRAMES)}")
        print(f"  ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿Ğ°Ñ€ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸: {ok_files}")
        coverage = (ok_files / (len(COINS) * len(TIMEFRAMES))) * 100 if len(COINS) * len(TIMEFRAMES) > 0 else 0
        print(f"  ĞŸĞ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ: {coverage:.1f}%")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PART 2: ML ĞœĞĞ”Ğ•Ğ›Ğ˜
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "-"*80)
    print("PART 2: ML MODELS")
    print("-"*80)

    model_files = []
    for model_dir in MODEL_DIRS:
        model_files.extend(find_files(model_dir, ['.json', '.pkl', '.joblib', '.h5']))

    if not model_files:
        print("âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹!")
    else:
        print(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: {len(model_files)}\n")

        print(f"{'Model Name':<50} {'Type':<15} {'Size KB':<10}")
        print("-" * 80)

        for filepath in sorted(model_files):
            info = check_model_file(filepath)
            name = filepath.name
            model_type = info.get('type', '?')
            size = info.get('size_kb', 0)

            status_icon = "âœ…" if info.get('status') == 'OK' else "âŒ"
            print(f"{status_icon} {name:<48} {model_type:<15} {size:<10.1f}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PART 3: Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ ĞŸĞ ĞĞ•ĞšĞ¢Ğ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "-"*80)
    print("PART 3: PROJECT STRUCTURE")
    print("-"*80)

    key_dirs = {
        'data': PROJECT_ROOT / 'data',
        'models': PROJECT_ROOT / 'models',
        'scripts': PROJECT_ROOT / 'scripts',
        'backtesting': PROJECT_ROOT / 'backtesting',
        'features': PROJECT_ROOT / 'features',
        'lib': PROJECT_ROOT / 'lib',
        'reports': PROJECT_ROOT / 'reports',
    }

    print("\nĞ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°:")
    for name, path in key_dirs.items():
        if path.exists():
            file_count = len(list(path.glob('*')))
            print(f"  âœ… {name:<15} ({file_count} files)")
        else:
            print(f"  âŒ {name:<15} (NOT FOUND)")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PART 4: Ğ’ĞĞ–ĞĞ«Ğ• Ğ¤ĞĞ™Ğ›Ğ«
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "-"*80)
    print("PART 4: KEY PROJECT FILES")
    print("-"*80)

    important_files = {
        'backtest_pjs_framework.py': PROJECT_ROOT / 'backtesting' / 'backtest_pjs_framework.py',
        'opportunity_scorer.py': PROJECT_ROOT / 'lib' / 'opportunity_scorer.py',
        'test_pjs_framework_v1.py': PROJECT_ROOT / 'scripts' / 'test_pjs_framework_v1.py',
    }

    for name, path in important_files.items():
        if path.exists():
            size = path.stat().st_size
            print(f"  âœ… {name:<40} ({size:>10,} bytes)")
        else:
            print(f"  âŒ {name:<40} NOT FOUND")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PART 5: SUMMARY & RECOMMENDATIONS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    print("\n" + "="*80)
    print("SUMMARY & RECOMMENDATIONS")
    print("="*80)

    if ok_files > 0:
        print(f"\nâœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {ok_files} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² OHLCV Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸")
        print(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(model_files)} ML Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹")
        print("\nğŸš€ Ğ“ĞĞ¢ĞĞ’Ğ« Ğš Ğ¡ĞŸĞ Ğ˜ĞĞ¢Ğ£!")
        print("\nĞ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸:")
        print("  1. Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ 15m Ğ¸Ğ»Ğ¸ 1h)")
        print("  2. Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½ÑƒÑ Ğ¼Ğ¾Ğ½ĞµÑ‚Ñƒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ BTC)")
        print("  3. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ train/test split (2020-2023 train, 2024 test)")
        print("  4. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ V1 baseline Ñ‚ĞµÑÑ‚ Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
        print("  5. Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ 48-hour sprint Ğ¿Ğ»Ğ°Ğ½")
    else:
        print("\nâš ï¸ ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ: ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ÑĞ¿Ñ€Ğ¸Ğ½Ñ‚Ğ°!")
        print("\nĞÑƒĞ¶Ğ½Ğ¾:")
        print("  1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· DVC (git lfs pull, dvc pull)")
        print("  2. Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ÑŒÑÑ Ñ‡Ñ‚Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ½Ñ‹ Ğ² data/raw/")
        print("  3. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ¾Ñ‚ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·")

    print("\n" + "="*80)

if __name__ == '__main__':
    main()
